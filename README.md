# Google-Cloud-Server-Project

The Following project was for my CIS 415 class at Arizona State University.

The goal was to get a better understanding of how to use Google Cloud Platform. 
I created two data sets called big_fraud_detection_dataset and small_fraud_detection_dataset that were generated by ChatGPT. 
The big_fraud_detection_dataset is not in this repository due to the size of the file being too large to upload.
The Professor provided me with some code in order to connect to Google Cloud Platform's Cloud Storage were I had to store the two datasets.
I had to modify his code so that it would connect to my buckets in the Cloud Storage and ensured that PySpark was working correctly in Google Colab before moving on to GCP Dataproc Jupyter.
I quickly found out that there were some issues with the dataset being converted into Spark due to the dataset was not displaying the rows properly.
At first I thought that it could have been due to a formating issue but, that wasn't the case.
After a couple changes in the code I found out that there were missing values in the dataset that ChatGPT provided me.
Which left me surprised because one of the parameters that I gave it was that it would not have missing values.
So, I decided to drop all the rows that had missing data from the dataset and the PySpark conversion was a success.
I was then instructed by the professor to give ChatGPT a text prompt with some perameters to process the data.
Some of the requirements that I gave it was to create two MLs (Logistic Regression and Random Forest) and put them against each other to see which one predicted cases of fraud more accurately.
I had to intervene in order to get the code to run properly.
Once I saw that the data for the small dataframe was processed correctly I setup the GCP dataproc and ran the same code but with the large dataset

